{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02372efc",
   "metadata": {},
   "source": [
    "## Multi-Class Classifier \n",
    "\n",
    "The goal of the following code is to create a multiclass classifier that utilizes logistic regression. The data will be fit with a \"train.csv\" that trains our model on appropriate features and labels. The data will then be fed new text from \"test.csv\" and predict labels per datapoint to indicate whether that datapoint is (0) not a movie or TV show review (1) a positive movie or TV show review or (2) a negative movie or TV show review. To run the code, please edit the paths with your own .csv paths. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e54697",
   "metadata": {},
   "source": [
    "## Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71a74e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e3449",
   "metadata": {},
   "source": [
    "## Reading in Test Data\n",
    "\n",
    "First, we'll need to read in and analyze the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e95711d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['ID', 'TEXT', 'LABEL']\n",
    "data = pd.read_csv(r\"path_to_your_csv_here\",header=0,names=columns)\n",
    "\n",
    "#to view the data format, you can uncomment the below:\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908349df",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Second, we'll need to transform our 'TEXT' column from train.csv into a feature vector. Similarly, we need to convert the 'LABEL' column into a label vector. Once those vectors have been created, we can train our model using those vectors and adjust our LogisticRegression parameters as necessary.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26de2510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating features from the text\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(data['TEXT'].apply(lambda x: np.str_(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90ebfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating labels from the text\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(data['LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ea275bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "LR = LogisticRegression(max_iter=10000, random_state=42)\n",
    "model = LR.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c1769e",
   "metadata": {},
   "source": [
    "## Adding in Test Data\n",
    "\n",
    "Now that our model has been fit, we can prepare and analyze the test data. Once we have confirmed the integrity of the test data, we can create a new feature vector for the 'TEXT' column to be fed into the fitted model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ccfd863",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(r\"path_to_your_csv_here\")\n",
    "\n",
    "#to view the data, you can uncomment the below:\n",
    "#data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51d0bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating features from test data\n",
    "cv2 = CountVectorizer()\n",
    "x2 = cv.transform(data2['TEXT'].apply(lambda x: np.str_(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09a8574",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "Now we can create our predictions for the new feature vector for the test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82a0511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = LR.predict(x2)\n",
    "\n",
    "#to confirm the shape and length of the vector, you can run the following print statements:\n",
    "#print(predictions)\n",
    "#print(len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b7a348",
   "metadata": {},
   "source": [
    "## Outputting Our Results \n",
    "\n",
    "In order to make our results available to others, we can create a new .csv through the pandas module. In this case, since we are interested in the test.csv 'ID' column and the predictions for those IDs, we just need to create those two columns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee8577e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the final .csv\n",
    "final_csv = pd.DataFrame({\"ID\":list(data2[\"ID\"]), \"LABEL\":list(predictions)})\n",
    "\n",
    "#outputting it to my desktop for saving and sharing outside of Jupyter\n",
    "final_csv.to_csv(r\"path_you_would_like_to_export_to\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934e305a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
